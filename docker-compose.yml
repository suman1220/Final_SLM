version: '3.8'

services:
  medical-chatbot:
    build:
      context: .
      dockerfile: Dockerfile
    container_name: diabetes-care-chatbot
    ports:
      - "8001:8001"
    environment:
      - MODEL_PATH=model.gguf
      - LLM_THREADS=6
      - LLM_BATCH=256
      - MAX_TOKENS=150
    volumes:
      # Mount model file from host (model.gguf not included in image due to size)
      - ./model.gguf:/app/model.gguf:ro
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8001/api/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 40s
    deploy:
      resources:
        limits:
          cpus: '4'
          memory: 4G
        reservations:
          cpus: '2'
          memory: 2G
